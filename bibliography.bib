@inproceedings{Rusu_2011_pcl,
abstract = {With the advent of new, low-cost 3D sensing hardware such as the Kinect, and continued efforts in advanced point cloud processing, 3D perception gains more and more importance in robotics, as well as other fields. In this paper we present one of our most recent initiatives in the areas of point cloud perception: PCL (Point Cloud Library - http://pointclouds.org). PCL presents an advanced and extensive approach to the subject of 3D perception, and it's meant to provide support for all the common 3D building blocks that applications need. The library contains state-of-the art algorithms for: filtering, feature estimation, surface reconstruction, registration, model fitting and segmentation. PCL is supported by an international community of robotics and perception researchers. We provide a brief walkthrough of PCL including its algorithmic capabilities and implementation strategies.},
author = {Rusu, R B and Cousins, S},
booktitle = {2011 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5980567},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/3D  is  here{\_}  Point  Cloud  Library  (PCL){\_}2011{\_}Rusu.pdf:pdf},
issn = {1050-4729},
keywords = {3D building blocks,3D perception gains,Kinect,PCL,advanced point cloud processing,feature estimation,feature extraction,image segmentation,international robotics community,low-cost 3D sensing hardware,model fitting,point cloud library,robot vision,surface reconstruction,surface registration,surface segmentation},
pages = {1--4},
title = {{3D is here: Point Cloud Library (PCL)}},
year = {2011}
}
@inproceedings{Elbaz_2017_3dpoint,
abstract = {We present an algorithm for registration between a large-scale point cloud and a close-proximity scanned point cloud, providing a localization solution that is fully independent of prior information about the initial positions of the two point cloud coordinate systems. The algorithm, denoted LORAX, selects super-points--local subsets of points--and describes the geometric structure of each with a low-dimensional descriptor. These descriptors are then used to infer potential matching regions for an efficient coarse registration process, followed by a fine-tuning stage. The set of super-points is selected by covering the point clouds with overlapping spheres, and then filtering out those of low-quality or nonsalient regions. The descriptors are computed using state-of-the-art unsupervised machine learning, utilizing the technology of deep neural network based auto-encoders. Abstract This novel framework provides a strong alternative to the common practice of using manually designed key-point descriptors for coarse point cloud registration. Utilizing super-points instead of key-points allows the available geometrical data to be better exploited to find the correct transformation. Encoding local 3D geometric structures using a deep neural network auto-encoder instead of traditional descriptors continues the trend seen in other computer vision applications and indeed leads to superior results. The algorithm is tested on challenging point cloud registration datasets, and its advantages over previous approaches as well as its robustness to density changes, noise, and missing data are shown.},
author = {Elbaz, Gil and Avraham, Tamar and Fischer, Anath},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/3D Point Cloud Registration for Localization Using a Deep Neural Network Auto-Encoder{\_}Elbaz{\_}2017{\_}edited.pdf:pdf},
title = {{3D Point Cloud Registration for Localization Using a Deep Neural Network Auto-Encoder}},
year = {2017}
}
@inproceedings{6758588,
abstract = {3D point cloud segmentation is the process of classifying point clouds into multiple homogeneous regions, the points in the same region will have the same properties. The segmentation is challenging because of high redundancy, uneven sampling density, and lack explicit structure of point cloud data. This problem has many applications in robotics such as intelligent vehicles, autonomous mapping and navigation. Many authors have introduced different approaches and algorithms. In this survey, we examine methods that have been proposed to segment 3D point clouds. The advantages, disadvantages, and design mechanisms of these methods are analyzed and discussed. Finally, we outline the promising future research directions.},
author = {Nguyen, A and Le, B},
booktitle = {2013 6th IEEE Conference on Robotics, Automation and Mechatronics (RAM)},
doi = {10.1109/RAM.2013.6758588},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/3D point cloud segmentation{\_} A survey{\_}Nguyen{\_}2013{\_}edited.pdf:pdf},
issn = {2158-219X},
keywords = {3D point cloud segmentation,Feature extraction,Image edge detection,Image segmentation,Robots,Robustness,Shape,Three-dimensional displays,autonomous mapping,autonomous navigation,image classification,image segmentation,intelligent vehicles,point cloud classification,robot vision,robotics},
month = {nov},
pages = {225--230},
title = {{3D point cloud segmentation: A survey}},
year = {2013}
}
@inproceedings{Yew_2018_3dfeat,
abstract = {In this paper, we propose the 3DFeat-Net which learns both 3D feature detector and descriptor for point cloud matching using weak supervision. Unlike many existing works, we do not require manual annotation of matching point clusters. Instead, we leverage on alignment and attention mechanisms to learn feature correspondences from GPS/INS tagged 3D point clouds without explicitly specifying them. We create training and benchmark outdoor Lidar datasets, and experiments show that 3DFeat-Net obtains state-of-the-art performance on these gravity-aligned datasets.},
address = {Cham},
author = {Yew, Zi Jian and Lee, Gim Hee},
booktitle = {European Conference on Computer Vision (ECCV) 2018},
editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/3DFeat-Net{\_} Weakly supervised local 3D features for point cloud registration{\_}Yew{\_}2018.pdf:pdf},
isbn = {978-3-030-01267-0},
pages = {630--646},
publisher = {Springer International Publishing},
title = {{3DFeat-Net: Weakly Supervised Local 3D Features for Point Cloud Registration}},
year = {2018}
}
@article{Bazin_2013_abranchandbound,
abstract = {Data correspondence/grouping under an unknown parametric model is a fundamental topic in computer vision. Finding feature correspondences between two images is probably the most popular application of this research field, and is the main motivation of our work. It is a key ingredient for a wide range of vision tasks, including three-dimensional reconstruction and object recognition. Existing feature correspondence methods are based on either local appearance similarity or global geometric consistency or a combination of both in some heuristic manner. None of these methods is fully satisfactory, especially in the presence of repetitive image textures or mismatches. In this paper, we present a new algorithm that combines the benefits of both appearance-based and geometry-based methods and mathematically guarantees a global optimization. Our algorithm accepts the two sets of features extracted from two images as input, and outputs the feature correspondences with the largest number of inliers, which verify both the appearance similarity and geometric constraints. Specifically, we formulate the problem as a mixed integer program and solve it efficiently by a series of linear programs via a branch-and-bound procedure. We subsequently generalize our framework in the context of data correspondence/grouping under an unknown parametric model and show it can be applied to certain classes of computer vision problems. Our algorithm has been validated successfully on synthesized data and challenging real images. {\textcopyright} 1979-2012 IEEE.},
author = {Bazin, Jean Charles and Li, Hongdong and Kweon, In So and Demonceaux, C{\'{e}}dric and Vasseur, Pascal and Ikeuchi, Katsushi},
doi = {10.1109/TPAMI.2012.264},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/A branch-and-bound approach to correspondence and grouping problems{\_}Bazin{\_}2013{\_}edited.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Mixed integer programming,bilinearities,branch-and-bound,global optimization,quadratic constraint},
number = {7},
pages = {1565--1576},
title = {{A branch-and-bound approach to correspondence and grouping problems}},
volume = {35},
year = {2013}
}
@article{Brown_2019_afamily,
abstract = {We present a family of methods for 2D–3D registration spanning both deterministic and non-deterministic branch-and-bound approaches. Critically, the methods exhibit invariance to the underlying scene primitives, enabling e.g. points and lines to be treated on an equivalent basis, potentially enabling a broader range of problems to be tackled while maximising available scene information, all scene primitives being simultaneously considered. Being a branch-and-bound based approach, the method furthermore enjoys intrinsic guarantees of global optimality; while branch-and-bound approaches have been employed in a number of computer vision contexts, the proposed method represents the first time that this strategy has been applied to the 2D–3D correspondence-free registration problem from points and lines. Within the proposed procedure, deterministic and probabilistic procedures serve to speed up the nested branch-and-bound search while maintaining optimality. Experimental evaluation with synthetic and real data indicates that the proposed approach significantly increases both accuracy and robustness compared to the state of the art.},
author = {Brown, Mark and Windridge, David and Guillemaut, Jean Yves},
doi = {10.1016/j.patcog.2019.04.002},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/A family of globally optimal branch-and-bound algorithms for 2D–3D correspondence-free registration{\_}Brown{\_}2019.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {2D–3D registration,Branch-and-bound,Global optimisation,Multi-modal registration},
month = {sep},
pages = {36--54},
publisher = {Elsevier Ltd},
title = {{A family of globally optimal branch-and-bound algorithms for 2D–3D correspondence-free registration}},
url = {https://doi.org/10.1016/j.patcog.2019.04.002},
volume = {93},
year = {2019}
}
@inproceedings{Goebbels_2018_alinear,
abstract = {We match photogrammetric point clouds with 3D city models in order to texture their wall and roof polygons. Point clouds are generated by the Structure from Motion (SfM) algorithm from overlapping pictures and videos that in general do not have precise geo-referencing. Therefore, we have to align the clouds with the models' coordinate systems. We do this by matching corners of buildings, detected from the 3D point cloud, with vertices of model buildings that are given in CityGML format. Due to incompleteness of our point clouds and the low number of models' vertices, the standard registration algorithm ``Iterative Closest Point'' does not yield reliable results. Therefore, we propose a relaxation of a Mixed Integer Linear Program that first finds a set of correspondences between building model vertices and detected corners. Then, in a second step, we use a Linear Program to compute an optimal linear mapping based on these correspondences.},
address = {Cham},
author = {Goebbels, Steffen and Pohle-Fr{\"{o}}hlich, Regina and Kant, Philipp},
booktitle = {Operations Research Proceedings 2017},
editor = {Kliewer, Natalia and Ehmke, Jan Fabian and Bornd{\"{o}}rfer, Ralf},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/A Linear Program for Matching Photogrammetric Point Clouds with CityGML Building Models{\_}Goebbels{\_}2017{\_}edited.pdf:pdf},
isbn = {978-3-319-89920-6},
pages = {129--134},
publisher = {Springer International Publishing},
title = {{A Linear Program for Matching Photogrammetric Point Clouds with CityGML Building Models}},
year = {2018}
}
@article{Besl_1992_amethod,
abstract = {The authors describe a general-purpose, representation-independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of 'shape complexity', one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model, prior to shape inspection. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces.{\textless}{\textgreater}},
author = {Besl, P J and McKay, N D},
doi = {10.1109/34.121791},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/A method for registration of 3-D shapes{\_}Besl{\_}1992.pdf:pdf},
issn = {1939-3539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D shape registration,Convergence,Inspection,Iterative algorithms,Iterative closest point algorithm,Iterative methods,Motion estimation,Quaternions,Shape measurement,Solid modeling,Testing,computational geometry,convergence,convergence of numerical methods,geometric entity,geometric model,iterative closest point,iterative methods,mean-square distance metric,optimisation,pattern recognition,picture processing,point set registration},
month = {feb},
number = {2},
pages = {239--256},
title = {{A method for registration of 3-D shapes}},
volume = {14},
year = {1992}
}
@article{Li_2015_amodified,
abstract = {This paper presents a modified ICP algorithm based on dynamic adjustment factor to speed up registration of point cloud and CAD model with high accuracy. The algorithm comes from a two-step optimization on the basic of original ICP. First, aiming at original ICP algorithm's time consuming in searching for corresponding point, we present a novel solution to search for the corresponding point based on STL (STereo Lithography) triangular mesh in CAD model. The solution makes full use of the advantages of STL file which consists of lists of facet data and vector information of triangular mesh to search for point cloud's corresponding points. Second, aiming at the algorithm's very slow iterative process, we put forward a kind of dynamic adjustment factor—the factor of dynamically adjusting the rigid transformation parameters which can make point cloud over-travel by rigid transformation along original trend in each iteration. When adding dynamic adjustment factor, the algorithm could search more effective corresponding points in next iteration, thus reducing the number of iterations and speeding up the registration. Experiments show that the modified ICP can effectively reduce time consuming in registration of point cloud and CAD model, meanwhile improving the registration accuracy.},
author = {Li, Weimin and Song, Pengfei},
doi = {https://doi.org/10.1016/j.patrec.2015.07.019},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/A modified ICP algorithm based on dynamic adjustment factor forregistration of point cloud and CAD model{\_}Li{\_}2015.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {CAD model,ICP algorithm,Point cloud,Registration,STL triangular mesh},
pages = {88--94},
title = {{A modified ICP algorithm based on dynamic adjustment factor for registration of point cloud and CAD model}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002287},
volume = {65},
year = {2015}
}
@article{ROB-035,
author = {Pomerleau, Fran{\c{c}}ois and Colas, Francis and Siegwart, Roland},
doi = {10.1561/2300000035},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/A Review of Point Cloud Registration Algorithms for Mobile Robotics{\_}Pomerleau{\_}2014.pdf:pdf},
issn = {1935-8253},
journal = {Foundations and Trends{\textregistered} in Robotics},
number = {1},
pages = {1--104},
title = {{A Review of Point Cloud Registration Algorithms for Mobile Robotics}},
url = {http://dx.doi.org/10.1561/2300000035},
volume = {4},
year = {2015}
}
@article{Pankaj_2015_arobust,
abstract = {The 3D modeling pipeline involves registration of partially overlapping 3D scans of an object. The automatic pairwise coarse alignment of partially overlapping 3D images is generally performed using 3D feature matching. The transformation estimation from matched features generally requires robust estimation due to the presence of outliers. RANSAC is a method of choice in problems where model estimation is to be done from data samples containing outliers. The number of RANSAC iterations depends on the number of data points and inliers to the model. Convergence of RANSAC can be very slow in the case of large number of outliers. This paper presents a novel algorithm for the 3D registration task which provides more accurate results in lesser computational time compared to RANSAC. The proposed algorithm is also compared against the existing modifications of RANSAC for 3D pairwise registration. The results indicate that the proposed algorithm tends to obtain the best 3D transformation matrix in lesser time compared to the other algorithms.},
author = {Pankaj, Dhanya S. and Nidamanuri, Rama Rao},
doi = {10.5566/ias.1378},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/A Robust Estimation Technique for 3D Point Cloud Registration{\_}Pankaj{\_}2015{\_}edited.pdf:pdf},
issn = {18545165},
journal = {Image Analysis and Stereology},
keywords = {3D registration,RANSAC,Robust estimation},
number = {1},
pages = {15--28},
title = {{A robust estimation technique for 3D point cloud registration}},
volume = {35},
year = {2015}
}
@inproceedings{Sakakubara_2007_automatic,
abstract = {A coarse registration method using Mixed Integer Linear Programming (MILP) is described that finds global optimal registration parameter values that are independent of the values of invariant features. We formulate the range image registration problem using MILP. Our algorithm using MILP formulation finds the best balanced optimal registration for robustly aligning two range images with the best balanced accuracy. It adjusts the error tolerance automatically in accordance with the accuracy of the given range image data. Experimental results show that this method of coarse registration is highly effective.},
author = {Sakakubara, Shizu and Kounoike, Yuusuke and Shinano, Yuji and Shimizu, Ikuko},
booktitle = {Asian Conference on Computer Vision},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Automatic range image registration using mixed integer linear programming{\_}Sakakubara{\_}2007{\_}edited.pdf:pdf},
organization = {Springer},
pages = {424--434},
title = {{Automatic range image registration using mixed integer linear programming}},
year = {2007}
}
@article{ochmann2016automatic,
abstract = {We present an automatic approach for the reconstruction of parametric 3D building models from indoor point clouds. While recently developed methods in this domain focus on mere local surface reconstructions which enable e.g. efficient visualization, our approach aims for a volumetric, parametric building model that additionally incorporates contextual information such as global wall connectivity. In contrast to pure surface reconstructions, our representation thereby allows more comprehensive use: first, it enables efficient high-level editing operations in terms of e.g. wall removal or room reshaping which always result in a topologically consistent representation. Second, it enables easy taking of measurements like e.g. determining wall thickness or room areas. These properties render our reconstruction method especially beneficial to architects or engineers for planning renovation or retrofitting. Following the idea of previous approaches, the reconstruction task is cast as a labeling problem which is solved by an energy minimization. This global optimization approach allows for the reconstruction of wall elements shared between rooms while simultaneously maintaining plausible connectivity between all wall elements. An automatic prior segmentation of the point clouds into rooms and outside area filters large-scale outliers and yields priors for the definition of labeling costs for the energy minimization. The reconstructed model is further enriched by detected doors and windows. We demonstrate the applicability and reconstruction power of our new approach on a variety of complex real-world datasets requiring little or no parameter adjustment.},
author = {Ochmann, Sebastian and Vock, Richard and Wessel, Raoul and Klein, Reinhard},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Automatic reconstruction of parametric building models from indoor point clouds{\_}Ochmann{\_}2016{\_}edited.pdf:pdf},
journal = {Computers {\&} Graphics},
pages = {94--103},
publisher = {Elsevier},
title = {{Automatic reconstruction of parametric building models from indoor point clouds}},
volume = {54},
year = {2016}
}
@inproceedings{Ding_2018_aerialimagery,
abstract = {A fast 3D model reconstruction methodology is desirable in many applications such as urban planning, training, and simulations. In this paper, we develop an automated algorithm for texture mapping oblique aerial images onto a 3D model generated from airborne light detection and ranging (LiDAR) data. Our proposed system consists of two steps. In the first step, we combine vanishing points and global positioning system aided inertial system readings to roughly estimate the extrinsic parameters of a calibrated camera. In the second step, we refine the coarse estimate of the first step by applying a series of processing steps. Specifically, We extract 2D corners corresponding to orthogonal 3D structural corners as features from both images and the untextured 3D LiDAR model. The correspondence between an image and the 3D model is then performed using Hough transform and generalized M-estimator sample consensus. The resulting 2D corner matches are used in Lowepsilas algorithm to refine camera parameters obtained earlier. Our system achieves 91{\%} correct pose recovery rate for 90 images over the downtown Berkeley area, and overall 61{\%} accuracy rate for 358 images over the residential, downtown and campus portions of the city of Berkeley.},
author = {{Min Ding} and Lyngbaek, K and Zakhor, A},
booktitle = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2008.4587661},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Automatic registration of aerial imagery with untextured 3D LiDAR models{\_}Ding{\_}2008.pdf:pdf},
issn = {1063-6919},
keywords = {3D model reconstruction methodology,Application software,Berkeley,Cameras,Clouds,Computational modeling,Geometry,Hough transform,Hough transforms,Image generation,Image reconstruction,Laser radar,Solid modeling,Urban planning,aerial imagery registration,calibrated camera,generalized M-estimator,geophysical signal processing,global positioning system,image reconstruction,image registration,image texture,inertial system readings,light detection and ranging,optical radar,pose estimation,pose recovery,radar imaging,remote sensing by laser beam,terrain mapping,texture mapping,untextured 3D LiDAR models},
pages = {1--8},
title = {{Automatic registration of aerial imagery with untextured 3D LiDAR models}},
year = {2008}
}
@misc{citygml2stl_online,
annote = {Accessed: 2020-04-15},
author = {Hron{\v{c}}ok, Miro},
booktitle = {PyPI},
title = {citygml2stl},
url = {https://pypi.org/project/citygml2stl/}
}
@article{Quan_2020_com,
abstract = {This article presents an efficient and robust estimator called compatibility-guided sampling consensus (CG-SAC) to achieve accurate 3-D point cloud registration. For correspondence-based registration methods, the random sample consensus (RANSAC) is served as a de facto solution for rigid transformation estimation from a number of feature correspondences. Unfortunately, RANSAC still suffers from two major limitations. First, it generates a hypothesis with at least three samples and desires a very large number of iterations to attain reasonable results, making it relatively time consuming. Second, the randomness during sampling can result in inaccurate results as it is highly potential to miss the optimal hypothesis. To solve these problems, we propose a compatibility-guided sampling strategy to eliminate randomness during sampling. In particular, only two correspondences are required by our method for hypothesis generation. We then rank correspondence pairs according to their compatibility scores because compatible correspondences are more likely to be correct and can yield more reasonable hypotheses. In addition, we propose a new geometric constraint named the distance between salient points (DSP) to measure the compatibility of two correspondences. Experiments on a set of real-world point cloud data with different application contexts and data modalities confirm the effectiveness of the proposed method. Comparison with several state-of-the-art estimators demonstrates the overall superiority of our CG-SAC estimator with regards to precision and time efficiency.},
author = {Quan, S and Yang, J},
doi = {10.1109/TGRS.2020.2982221},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Compatibility-Guided Sampling Consensusfor 3-D Point Cloud Registration{\_}Quan{\_}2020{\_}edited.pdf:pdf},
issn = {1558-0644},
journal = {IEEE Transactions on Geoscience and Remote Sensing (2020)},
keywords = {Feature correspondences,geometric compatibility,geometric constraint,point cloud registration,transformation estimation.},
pages = {1--13},
title = {{Compatibility-Guided Sampling Consensus for 3-D Point Cloud Registration}},
year = {2020}
}
@inproceedings{Wang_2019_deepclosest,
abstract = {Point cloud registration is a key problem for computer vision applied to robotics, medical imaging, and other applications. This problem involves finding a rigid transformation from one point cloud into another so that they align. Iterative Closest Point (ICP) and its variants provide simple and easily-implemented iterative methods for this task, but these algorithms can converge to spurious local optima. To address local optima and other difficulties in the ICP pipeline, we propose a learning-based method, titled Deep Closest Point (DCP), inspired by recent techniques in computer vision and natural language processing. Our model consists of three parts: a point cloud embedding network, an attention-based module combined with a pointer generation layer to approximate combinatorial matching, and a differentiable singular value decomposition (SVD) layer to extract the final rigid transformation. We train our model end-to-end on the ModelNet40 dataset and show in several settings that it performs better than ICP, its variants (e.g., Go-ICP, FGR), and the recently-proposed learning-based method PointNetLK. Beyond providing a state-of-the-art registration technique, we evaluate the suitability of our learned features transferred to unseen objects. We also provide preliminary analysis of our learned model to help understand whether domain-specific and/or global features facilitate rigid registration.},
author = {Wang, Yue and Solomon, Justin M},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Deep Closest Point{\_} Learning Representations for Point Cloud Registration{\_}Wang{\_}2019.pdf:pdf},
title = {{Deep Closest Point: Learning Representations for Point Cloud Registration}},
year = {2019}
}
@article{Lu_2019_deepicp,
archivePrefix = {arXiv},
arxivId = {1905.04153},
author = {Lu, Weixin and Wan, Guowei and Zhou, Yao and Fu, Xiangyu and Yuan, Pengfei and Song, Shiyu},
eprint = {1905.04153},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/DeepICP{\_} An End-to-End Deep Neural Network for 3D Point Cloud Registration{\_}Lu{\_}2019{\_}edited.pdf:pdf},
journal = {CoRR},
title = {{DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration}},
url = {http://arxiv.org/abs/1905.04153},
volume = {abs/1905.0},
year = {2019}
}
@inproceedings{Ding_2019_deepmapping,
abstract = {We propose DeepMapping, a novel registration framework using deep neural networks (DNNs) as auxiliary functions to align multiple point clouds from scratch to a globally consistent frame. We use DNNs to model the highly non-convex mapping process that traditionally involves hand-crafted data association, sensor pose initialization, and global refinement. Our key novelty is that "training" these DNNs with properly defined unsupervised losses is equivalent to solving the underlying registration problem, but less sensitive to good initialization than ICP. Our framework contains two DNNs: a localization network that estimates the poses for input point clouds, and a map network that models the scene structure by estimating the occupancy status of global coordinates. This allows us to convert the registration problem to a binary occupancy classification, which can be solved efficiently using gradient-based optimization. We further show that DeepMapping can be readily extended to address the problem of Lidar SLAM by imposing geometric constraints between consecutive point clouds. Experiments are conducted on both simulated and real datasets. Qualitative and quantitative comparisons demonstrate that DeepMapping often enables more robust and accurate global registration of multiple point clouds than existing techniques. Our code is available at https://ai4ce.github.io/DeepMapping/.},
author = {Ding, Li and Feng, Chen},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/DeepMapping{\_} Unsupervised Map Estimation From Multiple Point Clouds{\_}Ding{\_}2019{\_}edited.pdf:pdf},
title = {{DeepMapping: Unsupervised Map Estimation From Multiple Point Clouds}},
year = {2019}
}
@misc{DeutscherFeuerweherverband_online,
annote = {Accessed on 05/31/2020},
title = {{Deutscher Feuerwehrverband: Feuerwehr-Statistik}},
url = {https://www.feuerwehrverband.de/presse/statistik/}
}
@article{Wang_2019_dynamic,
abstract = {Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information, so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing properties: It incorporates local neighborhood information; it can be stacked applied to learn global shape properties; and in multi-layer systems affinity in feature space captures semantic characteristics over potentially long distances in the original embedding. We show the performance of our model on standard benchmarks, including ModelNet40, ShapeNetPart, and S3DIS.},
archivePrefix = {arXiv},
arxivId = {1801.07829},
author = {Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E. and Bronstein, Michael M. and Solomon, Justin M},
eprint = {1801.07829},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Dynamic graph cnn for learning on point clouds{\_}Wang{\_}2019.pdf:pdf},
issn = {15577368},
journal = {ACM Transactions on Graphics},
keywords = {Classification,Point cloud,Segmentation},
number = {5},
pages = {Article 146},
title = {{Dynamic graph cnn for learning on point clouds}},
volume = {38},
year = {2019}
}
@article{Huang_2020_feature,
author = {Huang, Xiaoshui and Mei, Guofeng and Zhang, Jian},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Feature-metric Registration{\_} A Fast Semi-supervised Approach for Robust Point Cloud Registration without Correspondences{\_}Huang{\_}2020.pdf:pdf},
journal = {arXiv preprint arXiv:2005.01014},
title = {{Feature-metric Registration: A Fast Semi-supervised Approach for Robust Point Cloud Registration without Correspondences}},
year = {2020}
}
@inproceedings{Kim_2011_fully,
abstract = {In construction automation applications, registration between the 3D computer-aided design (CAD) model and the point cloud obtained by remote sensing technology is an important process such as progress monitoring and as-built modeling. However, the registration method to align the 3D CAD model and point cloud in construction automation has limitations because the registration is performed manually, which is less accurate and more time-consuming. In this paper, an automated registration method for a 3D CAD model with point cloud from the construction site is proposed. Preprocessing is presented to convert points into suitable representation for registration. Then, an automated registration method that determines transformation parameters is presented. Field experiments have been conducted to test the proposed registration method and the results show that the proposed method is useful for construction automation.},
author = {Kim, Changmin and Lee, Joohyuk and Cho, Minwoo and Kim, Changwan},
booktitle = {28th International Symposium on Automation and Robotics in Construction, Seoul, Korea},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Fully automated registration of 3D CAD models with point cloud from construction sites{\_}Kim{\_}2011{\_}edited.pdf:pdf},
pages = {917--922},
title = {{Fully automated registration of 3D CAD model with point cloud from construction site}},
year = {2011}
}
@article{Kim_2013_fully,
abstract = {Alignment of the 3D data with the 3D CAD model allows for analysis of the progress of the construction project or retrieval of the desired 3D object model for use in 3D as-built modeling. The aim of this study was to propose a fully automated registration process that allows for alignment of the 3D data with the 3D CAD model. The resulting process encompasses three pre-processing steps: point cloud representation, noise filtering, and data re-sampling. Then, after the pre-processing stage, a two-step global-to-local registration procedure is applied: PCA-based global registration followed by a local registration technique that uses ICP and the Levenberg–Marquardt algorithm. The proposed process was tested through a field experiment. The experimental results demonstrate that the proposed process is not only capable of fully automating the registration of 3D data to a 3D CAD model but also beneficial for use in project progress monitoring.},
author = {Kim, Changmin and Son, Hyojoo and Kim, Changwan},
doi = {https://doi.org/10.1016/j.autcon.2013.01.005},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Fully automated registration of 3D data to a 3D CAD model for project progress monitoring{\_}Kim{\_}2013{\_}edited.pdf:pdf},
issn = {0926-5805},
journal = {Automation in Construction},
keywords = {3D CAD model,3D data,Construction automation,Project progress monitoring,Scene-to-model registration},
pages = {587--594},
title = {{Fully automated registration of 3D data to a 3D CAD model for project progress monitoring}},
url = {http://www.sciencedirect.com/science/article/pii/S0926580513000071},
volume = {35},
year = {2013}
}
@article{Segal_2009_generalizedicp,
abstract = {— In this paper we combine the Iterative Closest Point ('ICP') and 'point-to-plane ICP' algorithms into a single probabilistic framework. We then use this framework to model locally planar surface structure from both scans instead of just the " model " scan as is typically done with the point-to-plane method. This can be thought of as 'plane-to-plane'. The new approach is tested with both simulated and real-world data and is shown to outperform both standard ICP and point-to-plane. Furthermore, the new approach is shown to be more robust to incorrect correspondences, and thus makes it easier to tune the maximum match distance parameter present in most variants of ICP. In addition to the demonstrated performance improvement, the proposed model allows for more expressive probabilistic models to be incorporated into the ICP framework. While maintaining the speed and simplicity of ICP, the Generalized-ICP could also allow for the addition of outlier terms, measurement noise, and other probabilistic techniques to increase robustness.},
author = {Segal, Aleksandr V and Haehnel, Dirk and Thrun, Sebastian},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Generalized-ICP{\_}Segal{\_}2009{\_}edited.pdf:pdf},
isbn = {9780262514637},
journal = {Robotics: science and systems},
keywords = {ICP,point-to-plane,point-to-point,registration},
pages = {435},
title = {{Generalized-ICP}},
volume = {2},
year = {2009}
}
@inproceedings{Brown_2015_globally,
abstract = {We present a novel approach to 2D-3D registration from points or lines without correspondences. While there exist established solutions in the case where correspondences are known, there are many situations where it is not possible to reliably extract such correspondences across modalities, thus requiring the use of a correspondence-free registration algorithm. Existing correspondence-free methods rely on local search strategies and consequently have no guarantee of finding the optimal solution. In contrast, we present the first globally optimal approach to 2D-3D registration without correspondences, achieved by a Branch-and-Bound algorithm. Furthermore, a deterministic annealing procedure is proposed to speed up the nested branch-and-bound algorithm used. The theoretical and practical advantages this brings are demonstrated on a range of synthetic and real data where it is observed that the proposed approach is significantly more robust to high proportions of outliers compared to existing approaches.},
author = {Brown, Mark and Windridge, David and Guillemaut, Jean Yves},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2015.244},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Globally optimal 2D-3D registration from points or lines without correspondences{\_}Brown{\_}2015{\_}edited.pdf:pdf},
isbn = {9781467383912},
issn = {15505499},
pages = {2111--2119},
title = {{Globally optimal 2D-3D registration from points or lines without correspondences}},
volume = {2015 Inter},
year = {2015}
}
@article{Yang_2016_goicp,
abstract = {The Iterative Closest Point (ICP) algorithm is one of the most widely used methods for point-set registration. However, being based on local iterative optimization, ICP is known to be susceptible to local minima. Its performance critically relies on the quality of the initialization and only local optimality is guaranteed. This paper presents the first globally optimal algorithm, named Go-ICP, for Euclidean (rigid) registration of two 3D point-sets under the {\$}L{\_}2{\$} error metric defined in ICP. The Go-ICP method is based on a branch-and-bound scheme that searches the entire 3D motion space {\$}SE(3){\$} . By exploiting the special structure of {\$}SE(3){\$} geometry, we derive novel upper and lower bounds for the registration error function. Local ICP is integrated into the BnB scheme, which speeds up the new method while guaranteeing global optimality. We also discuss extensions, addressing the issue of outlier robustness. The evaluation demonstrates that the proposed method is able to produce reliable registration results regardless of the initialization. Go-ICP can be applied in scenarios where an optimal solution is desirable or where a good initialization is not always available.},
author = {Yang, J and Li, H and Campbell, D and Jia, Y},
doi = {10.1109/TPAMI.2015.2513405},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Go-ICP{\_} A Globally Optimal Solution to 3D ICP Point-Set Registration.pdf:pdf},
issn = {1939-3539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D point-set registration,Convergence,Iterative closest point algorithm,Optimization,Robustness,SE(3) space search,Three-dimensional displays,Yttrium,branch-and-bound,global optimization,iterative closest point},
month = {nov},
number = {11},
pages = {2241--2254},
title = {{Go-ICP: A Globally Optimal Solution to 3D ICP Point-Set Registration}},
volume = {38},
year = {2016}
}
@article{Breuel_2003_implementation,
abstract = {Algorithms for geometric matching and feature extraction that work by recursively subdividing transformation space and bounding the quality of match have been proposed in a number of different contexts and become increasingly popular over the last few years. This paper describes matchlist-based branch-and-bound techniques and presents a number of new applications of branch-and-bound methods, among them, a method for globally optimal partial line segment matching under bounded or Gaussian error, point matching under a Gaussian error model with subpixel accuracy and precise orientation models, and a simple and robust technique for finding multiple distinct object instances. It also contains extensive reference information for the implementation of such matching methods under a wide variety of error bounds and transformations. In addition, the paper contains a number of benchmarks and evaluations that provide new information about the runtime behavior of branch-and-bound matching algorithms in general, and that help choose among different implementation strategies, such as the use of point location data structures and space/time tradeoffs involving depthfirst search. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
author = {Breuel, Thomas M.},
doi = {10.1016/S1077-3142(03)00026-2},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Implementation techniques for geometric branch-and-bound matching methods{\_}Breuel{\_}2003{\_}edited.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Bounded error,Branch and bound,Gaussian error,Geometric matching,Global optimization,Maximum likelihood,Visual object recognition},
month = {jun},
number = {3},
pages = {258--294},
publisher = {Academic Press Inc.},
title = {{Implementation techniques for geometric branch-and-bound matching methods}},
volume = {90},
year = {2003}
}
@article{Oesau_2014_indoor,
abstract = {We present a method for automatic reconstruction of permanent structures, such as walls, floors and ceilings, given a raw point cloud of an indoor scene. The main idea behind our approach is a graph-cut formulation to solve an inside/outside labeling of a space partitioning. We first partition the space in order to align the reconstructed models with permanent structures. The horizontal structures are located through analysis of the vertical point distribution, while vertical wall structures are detected through feature preserving multi-scale line fitting, followed by clustering in a Hough transform space. The final surface is extracted through a graph-cut formulation that trades faithfulness to measurement data for geometric complexity. A series of experiments show watertight surface meshes reconstructed from point clouds measured on multi-level buildings.},
author = {Oesau, Sven and Lafarge, Florent and Alliez, Pierre},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Indoor scene reconstruction using feature sensitive primitive extraction and graph-cut{\_}Oesau{\_}2014{\_}edited.pdf:pdf},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
pages = {68--82},
publisher = {Elsevier},
title = {{Indoor scene reconstruction using feature sensitive primitive extraction and graph-cut}},
volume = {90},
year = {2014}
}
@article{Goebbels_2019_icpcitygml,
abstract = {The Iterative Closest Point algorithm (ICP) is a standard tool for registration of a source to a target point cloud. In this paper, ICP in point-to-plane mode is adopted to city models that are defined in CityGML. With this new point-to-model version of the algorithm, a coarsely registered photogrammetric point cloud can be matched with buildings? polygons to provide, e.g., a basis for automated 3D facade modeling. In each iteration step, source points are projected to these polygons to find correspondences. Then an optimization problem is solved to find an affine transformation that maps source points to their correspondences as close as possible. Whereas standard ICP variants do not perform scaling, our algorithm is capable of isotropic scaling. This is necessary because photogrammetric point clouds obtained by the structure from motion algorithm typically are scaled randomly. Two test scenarios indicate that the presented algorithm is faster than ICP in point-to-plane mode on sampled city models.},
author = {Goebbels, S and Pohle-Fr{\"{o}}hlich, R and Pricken, P},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Iterative Closest Point Algorithm for Accurate Registration of Coarsely Registered Point Clouds with CityGML Models{\_}Goebbels{\_}2019{\_}edited.pdf:pdf},
journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
pages = {201--208},
title = {{Iterative Closest Point Algorithm for Accurate Registration of Coarsely Registered Point Clouds with CityGML Models}},
year = {2019}
}
@article{Wu_2020_icp,
abstract = {Motivated by the high speed but insufficient precision of the existing fast point feature histogram algorithm, a new fast point feature histogram registration algorithm based on density optimization is proposed. In this method, a 44-section blank feature histogram is first established, and then a principal component analysis is implemented to calculate the normal of each point in the point cloud. By translating the coordinate system in the established local coordinate system, the normal angle of each point pair and its weighted neighborhood are obtained, and then a fast point feature histogram with 33 sections is established. The reciprocal of the volume density for the central point and its weighted neighborhood are calculated simultaneously. The whole reciprocal space is divided into 11 sections. Thus, a density fast point feature histogram with 44 sections is obtained. On inputting the testing models, the initial pose of the point cloud is adjusted using the traditional fast point feature histogram and the proposed algorithms, respectively. Then, the iterative closest point algorithm is incorporated to complete the fine registration test. Compared with the traditional fine registration test algorithm, the proposed optimization algorithm can obtain 44 feature parameters under the condition of a constant time complexity. Moreover, the proposed optimization algorithm can reduce the standard deviation by 8.6{\%} after registration. This demonstrates that the proposed method encapsulates abundant information and can achieve a high registration accuracy.},
author = {Wu, Lu-shen and Wang, Guo-lin and Hu, Yun},
doi = {10.1177/0020294019878869},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Iterative closest point registration for fast point feature histogram features of a volume density optimization algorithm{\_}Wu{\_}2019.pdf:pdf},
journal = {Measurement and Control},
number = {1-2},
pages = {29--39},
title = {{Iterative closest point registration for fast point feature histogram features of a volume density optimization algorithm}},
url = {https://doi.org/10.1177/0020294019878869},
volume = {53},
year = {2020}
}
@misc{Kompeten68:online,
annote = {Accessed on 05/13/2020},
title = {{Kompetenzzentrum f{\"{u}}r Rettungsrobotik}},
url = {https://rettungsrobotik.de/}
}
@article{Windheuser_2011_largescale,
abstract = {Abstract We study an algorithmic framework for computing an elastic orientation-preserving matching of non-rigid 3D shapes. We outline an Integer Linear Programming formulation whose relaxed version can be minimized globally in polynomial time. Because of the high number of optimization variables, the key algorithmic challenge lies in efficiently solving the linear program. We present a performance analysis of several Linear Programming algorithms on our problem. Furthermore, we introduce a multiresolution strategy which allows the matching of higher resolution models.},
author = {Windheuser, Thomas and Schlickwei, Ulrich and Schimdt, Frank R and Cremers, Daniel},
doi = {10.1111/j.1467-8659.2011.02021.x},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Large-scale integer linear pro- gramming for orientation preserving 3D shape matching{\_}Windheuser{\_}2011.pdf:pdf},
journal = {Computer Graphics Forum},
keywords = {I.3.5 Computer Graphics: Computational Geometry an},
number = {5},
pages = {1471--1480},
title = {{Large-Scale Integer Linear Programming for Orientation Preserving 3D Shape Matching}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2011.02021.x},
volume = {30},
year = {2011}
}
@article{Yu2020,
author = {Yu, Huai and Zhen, Weikun and Yang, Wen and Scherer, Sebastian},
doi = {10.1109/tim.2020.2999137},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Line-Based 2-D–3-D Registration and Camera Localization in Structured Environments{\_}Yu{\_}2020.pdf:pdf},
issn = {0018-9456},
journal = {IEEE Transactions on Instrumentation and Measurement},
month = {jun},
pages = {1--1},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{Line-based 2D-3D Registration and Camera Localization in Structured Environments}},
year = {2020}
}
@inproceedings{Goebbels_2018_linebased,
abstract = {This paper describes a method to align photogrammetric point clouds with CityGML 3D city models. Amongst others, we use photogrammetric point clouds that are generated from videos taken from the driver's perspective of a car. Clouds are computed with the Structure-from-Motion algorithm. We detect wall planes to rotate these clouds so that walls become vertical. This allows us to find buildings' footprints by accumulating points that are orthogonally projected to the ground. Thus, the main alignment step can be performed in 2D. To this end, we match detected footprints with corresponding footprints of CityGML models in a x-y-plane based on line segments. These line segments are detected using a probabilistic Hough transform. Then we apply a Mixed Integer Linear Program to find a maximum number of matching line segment pairs. Using a Linear Program, we optimize a rigid affine transformation to align the lines of these pairs. Finally, we use height information along CityGML terrain intersection lines to estimate scaling and translation in z-direction. By combining the results, we obtain an affine mapping that aligns the point cloud with the city model. Linear Programming is not widely applied to registration problems; however the technique presented is a fast alternative to Iterative Closest Point algorithms that align photogrammetric point clouds with clouds sampled from city models.},
author = {Goebbels, Steffen and Pohle-Froehlich, Regina},
booktitle = {Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISIGRAPP)},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Line-Based Registration of Photogrammetric Point Clouds with 3D City{\_}Goebbels{\_}2018{\_}edited.pdf:pdf},
title = {{Line-based Registration of Photogrammetric Point Clouds with 3D City Models by Means of Mixed Integer Linear Programming}},
year = {2018}
}
@book{Groger_2012_OGC,
abstract = {CityGML is an open data model and XML-based format for the storage and exchange of virtual 3D city models. It is an application schema for the Geography Markup Language version 3.1.1 (GML3), the extendible international standard for spatial data exchange issued by the Open Geospatial Consortium (OGC) and the ISO TC211. The aim of the development of CityGML is to reach a common definition of the basic entities, attributes, and relations of a 3D city model. This is especially important with respect to the cost-effective sustainable maintenance of 3D city models, allowing the reuse of the same data in different application fields.},
author = {Gr{\"{o}}ger, Gerhard and Kolbe, Thomas H and Nagel, Claus and H{\"{a}}fele, Karl-Heinz},
edition = {2.0.0},
publisher = {Open Geospatial Consortium},
title = {{OGC City Geography Markup Language (CityGML) Encoding Standard}},
year = {2012}
}
@article{sarode2019one,
author = {Sarode, Vinit and Li, Xueqian and Goforth, Hunter and Aoki, Yasuhiro and Dhagat, Animesh and Srivatsan, Rangaprasad Arun and Lucey, Simon and Choset, Howie},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/One Framework to Register Them All{\_} PointNet Encoding for Point Cloud Alignment{\_}Sarode{\_}2019.pdf:pdf},
journal = {arXiv preprint arXiv:1912.05766},
title = {{One Framework to Register Them All: PointNet Encoding for Point Cloud Alignment}},
year = {2019}
}
@article{Zhou_2018_open3d,
author = {Zhou, Qian-Yi and Park, Jaesik and Koltun, Vladlen},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Open3D{\_} A Modern Library for 3D Data Processing{\_}Zhou{\_}2018.pdf:pdf},
journal = {arXiv preprint arXiv:1801.09847},
title = {{Open3D: A modern library for 3D data processing}},
year = {2018}
}
@article{BOSCHE201290,
abstract = {With the development of building information modelling (BIM) and terrestrial laser scanning (TLS) in the architecture, engineering, construction and facility management (AEC/FM) industry, the registration of site laser scans and project 3D (BIM) models in a common coordinate system is becoming critical to effective project control. The co-registration of 3D datasets is normally performed in two steps: coarse registration followed by fine registration. Focusing on the coarse registration, model-scan registration has been well investigated in the past, but it is shown in this article that the context of the AEC/FM industry presents specific (1) constraints that make fully-automated registration very complex and often ill-posed, and (2) advantages that can be leveraged to develop simpler yet effective registration methods. This paper thus presents a novel semi-automated plane-based registration system for coarse registration of laser scanned 3D point clouds with project 3D models in the context of the AEC/FM industry. The system is based on the extraction of planes from the laser scanned point cloud and project 3D/4D model. Planes are automatically extracted from the 3D/4D model. For the point cloud data, two methods are investigated. The first one is fully automated, and the second is a semi-automated but effective one-click RANSAC-supported extraction method. In both cases, planes are then manually but intuitively matched by the user. Experiments, which compare the proposed system to software packages commonly used in the AEC/FM industry, demonstrate that at least as good registration quality can be achieved by the proposed system, in a simpler and faster way. It is concluded that, in the AEC/FM context, the proposed plane-based registration system is a compelling alternative to standard point-based registration techniques.},
author = {Bosch{\'{e}}, Fr{\'{e}}d{\'{e}}ric},
doi = {https://doi.org/10.1016/j.aei.2011.08.009},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Plane-based Registration of Construction Laser Scans with 3D-4D Building Models{\_}Bosche{\_}2011.pdf:pdf},
issn = {1474-0346},
journal = {Advanced Engineering Informatics},
keywords = {3D model,BIM,Coarse Registration,Construction,Laser Scan,Point Cloud},
number = {1},
pages = {90--102},
title = {{Plane-based registration of construction laser scans with 3D/4D building models}},
url = {http://www.sciencedirect.com/science/article/pii/S1474034611000784},
volume = {26},
year = {2012}
}
@inproceedings{Lu_2019_4pcsicp,
abstract = {A point cloud registration algorithm fusing of Super 4PCS and ICP based on the key point is proposed to solve the problem that the traditional Super 4PCS algorithm is time consuming and has poor registration accuracy for point clouds with low-overlap region. Firstly, by using the voxel grid method, point cloud is down-sampled to reduce the amount of the computation data. In order to reduce the search range of consistent four-point sets, keypoints are extracted by using ISS(Intrinsic Shape Signature) method. Then the optimal consistency four-point sets is obtained by Super4PCS based on extracted keypoints. We use each point in this four-point sets as the center to establish a neighborhood ball, and the overlapping regions is obtained by calculating the intersection of the neighborhood balls. Finally, registration is performed by using ICP within obtained overlapping regions. The experimental results show that the proposed method can improve the registration speed while improve the registration accuracy.},
author = {Lu, J and Wang, W and Shao, H and Su, L},
booktitle = {2019 Chinese Control Conference (CCC)},
doi = {10.23919/ChiCC.2019.8866059},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Point Cloud Registration Algorithm Fusing of Super 4PCS and ICP Based on the Key Points{\_}Lu{\_}2019{\_}edited.pdf:pdf},
issn = {1934-1768},
keywords = {Approximation algorithms,Data mining,Eigenvalues and eigenfunctions,Heuristic algorithms,ICP,ICP (Iterative Closest Point),ISS (Intrinsic Shape Signature),Indexes,Intrinsic Shape Signature,Shape,Super4PCS,Three-dimensional displays,computer graphics,image fusion,image registration,key points,overlapping region,overlapping regions,point cloud registration,point cloud registration algorithm fusion,shape recognition},
pages = {4439--4444},
title = {{Point Cloud Registration Algorithm Fusing of Super 4PCS and ICP Based on the Key Points}},
year = {2019}
}
@inproceedings{8742148,
abstract = {This paper presents an end-to-end 3D registration algorithm for relative navigation between known objects based on a point-to-CAD iterative closest point (ICP) principle. The objective of this method is to take in a measured point cloud extracted from a depth or disparity map - such as the ones obtained from stereo cameras, time-of-flight cameras, LiDARs, or depth from defocus sensors - and calculate the rigid body transformation that best aligns the measured data with a corresponding 3D CAD model. By leveraging the geometric information encoded into stereolithography (STL) files, it is sought to address the computational intractability imposed by the na{\"{i}}ve generation of dense target point clouds solely based on the target's known surface. To this end, the proposed approach computes a bijective projection onto the known triangular mesh to obtain a target point cloud with which to use ICP techniques for incremental alignment; the projection step is then carried on recursively until the convergence criteria are met, yielding a relative 6DOF pose between the two objects to be used within the estimation pipeline. Demonstrations of the algorithm are presented using simulated datasets; results include time complexity analyses for real-time operation cases, performance variation assessments with respect to CAD model complexity, and sensitivity analysis for determining the tolerance to distinct noise levels and spurious measurements. The design and implementation of the algorithm makes use of the open-source Point Cloud Library, and access to its source code is included within this work.},
author = {Espinoza, A T and Setterfield, T P},
booktitle = {2019 IEEE Aerospace Conference},
doi = {10.1109/AERO.2019.8742148},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Point-to-CAD 3D Registration Algorithm for Relative Navigation Using Depth-Based Maps{\_}Espinoza{\_}2019.pdf:pdf},
issn = {1095-323X},
keywords = {3D CAD model,CAD,ICP techniques,LiDARs,bijective projection,computational intractability,convergence criteria,dense target point cloud naive generation,depth from defocus sensors,depth-based maps,disparity map,end-to-end 3D registration algorithm,estimation pipeline,feature extraction,geometric information,image reconstruction,image registration,image sensors,iterative methods,navigation,noise levels,open-source point cloud library,performance variation assessments,point-to-CAD 3D registration algorithm,point-to-CAD iterative closest point principle,pose estimation,relative 6DOF pose,relative navigation,rigid body transformation,sensitivity analysis,solid modelling,source code,spurious measurements,stereo cameras,stereolithography,stereolithography files,time complexity analyses,time-of-flight cameras,triangular mesh},
pages = {1--7},
title = {{Point-to-CAD 3D Registration Algorithm for Relative Navigation Using Depth-Based Maps}},
year = {2019}
}
@techreport{Qi_2017_pointnetdeep,
abstract = {Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.},
author = {Qi, Charles Ruizhongtai and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/PointNet{\_} Deep Learning on Point Sets for 3D Classification and Segmentation{\_}Qi{\_}2016{\_}edited.pdf:pdf},
pages = {652--660},
title = {{PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation}},
year = {2017}
}
@inproceedings{Qi_2017_pointnet,
author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {Guyon, I and Luxburg, U V and Bengio, S and Wallach, H and Fergus, R and Vishwanathan, S and Garnett, R},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/PointNet++{\_} Deep Hierarchical Feature Learning on Point Sets in a Metric Space{\_}Qi{\_}2017.pdf:pdf},
pages = {5099--5108},
publisher = {Curran Associates, Inc.},
title = {{PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space}},
url = {http://papers.nips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf},
year = {2017}
}
@incollection{Moreno-Noguer2008,
abstract = {Estimating a camera pose given a set of 3D-object and 2Dimage feature points is a well understood problem when correspondences are given. However, when such correspondences cannot be established a priori, one must simultaneously compute them along with the pose. Most current approaches to solving this problem are too computationally intensive to be practical. An interesting exception is the SoftPosit algorithm, that looks for the solution as the minimum of a suitable objective function. It is arguably one of the best algorithms but its iterative nature means it can fail in the presence of clutter, occlusions, or repetitive patterns. In this paper, we propose an approach that overcomes this limitation by taking advantage of the fact that, in practice, some prior on the camera pose is often available. We model it as a Gaussian Mixture Model that we progressively refine by hypothesizing new correspondences. This rapidly reduces the number of potential matches for each 3D point and lets us explore the pose space more thoroughly than SoftPosit at a similar computational cost. We will demonstrate the superior performance of our approach on both synthetic and real data.},
author = {Moreno-Noguer, Francesc and Lepetit, Vincent and Fua, Pascal},
doi = {10.1007/978-3-540-88688-4_30},
month = {oct},
pages = {405--418},
publisher = {Springer, Berlin, Heidelberg},
title = {{Pose Priors for Simultaneously Solving Alignment and Correspondence}},
url = {https://link.springer.com/chapter/10.1007/978-3-540-88688-4{\_}30},
year = {2008}
}
@article{Fischler_1981_RANSAC,
address = {New York, NY, USA},
author = {Fischler, Martin A and Bolles, Robert C},
doi = {10.1145/358669.358692},
issn = {0001-0782},
journal = {Communications of the ACM},
keywords = {automated cartography,camera calibration,image matching,location determination,model fitting,scene analysis},
number = {6},
pages = {381--395},
publisher = {Association for Computing Machinery},
title = {{Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography}},
url = {https://doi.org/10.1145/358669.358692},
volume = {24},
year = {1981}
}
@article{Holy2016,
abstract = {Registration of LIDAR scans is an important problem in many applications that need to align two LIDAR scans optimally. This paper presents a novel algorithm for registration of LIDAR scans. The algorithm combines two already known but different concepts. The first one is the registration of lines and the second one is the registration in polar coordinates. The main idea is a new representation of the surrounding area that makes the mentioned combination possible. The algorithm works with lines, specifically with dynamic line segments in polar coordinates that are expressed as functions of angles. This representation significantly decreases the computation time and enhances the resulting alignment. The presented algorithm was designed for indoor environments that are rich in objects that can be represented by line segments. The algorithm has been tested with many indoor LIDAR scans and is able to align them with high accuracy and in real-time.},
author = {Hol{\'{y}}, Branislav},
doi = {10.1016/j.ifacol.2016.07.098},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Registration of Lines in 2D LIDAR Scans via Functions of Angles{\_}Holy{\_}2016{\_}edited.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {registration scan-matching lines lidar transformat},
month = {jan},
number = {5},
pages = {109--114},
publisher = {Elsevier B.V.},
title = {{Registration of Lines in 2D LIDAR Scans via Functions of Angles}},
volume = {49},
year = {2016}
}
@article{Fitzgibbon_2003_robust,
abstract = {This paper introduces a new method of registering point sets. The registration error is directly minimized using general-purpose non-linear optimization (the Levenberg–Marquardt algorithm). The surprising conclusion of the paper is that this technique is comparable in speed to the special-purpose Iterated Closest Point algorithm, which is most commonly used for this task. Because the routine directly minimizes an energy function, it is easy to extend it to incorporate robust estimation via a Huber kernel, yielding a basin of convergence that is many times wider than existing techniques. Finally, we introduce a data structure for the minimization based on the chamfer distance transform, which yields an algorithm that is both faster and more robust than previously described methods.},
author = {Fitzgibbon, Andrew W},
doi = {https://doi.org/10.1016/j.imavis.2003.09.004},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Robust registration of 2D and 3D point sets{\_}Fitzgibbon{\_}2003.pdf:pdf},
issn = {0262-8856},
journal = {Image and Vision Computing},
keywords = {Iterated Closest Point,Levenberg–Marquardt,Range image registration},
number = {13},
pages = {1145--1153},
title = {{Robust registration of 2D and 3D point sets}},
url = {http://www.sciencedirect.com/science/article/pii/S0262885603001835},
volume = {21},
year = {2003}
}
@article{yew2020rpm,
author = {Yew, Zi Jian and Lee, Gim Hee},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/RPM-Net{\_} Robust Point Matching using Learned Features{\_}Yew{\_}2020.pdf:pdf},
journal = {arXiv preprint arXiv:2003.13479},
title = {{RPM-Net: Robust Point Matching using Learned Features}},
year = {2020}
}
@inproceedings{David2003,
abstract = {We present a new robust line matching algorithm for solving the model-to-image registration problem. Given a model consisting of 3D lines and a cluttered perspective image of this model, the algorithm simultaneously estimates the pose of the model and the correspondences of model lines to image lines. The algorithm combines softassign for determing correspondences and POSIT for determining pose. Integrating these algorithms into a deterministic annealing procedure allows the correspondence and pose to evolve from initially uncertain values to a joint local optimum. This research extends to line features the SoftPOSIT algorithm proposed recently for point features. Lines detected in images are typically more stable than points and are less likely to be produced by clutter and noise, especially in man-made environments. Experiments on synthetic and real imagery with high levels of clutter, occlusion, and noise demonstrate the robustness of the algorithm.},
author = {David, Philip and DeMenthon, Daniel and Duraiswami, Ramani and Samet, Hanan},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr.2003.1211499},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Simultaneous pose and correspondence determination using line features{\_}David{\_}2003.pdf:pdf},
issn = {10636919},
title = {{Simultaneous pose and correspondence determination using line features}},
volume = {2},
year = {2003}
}
@article{David2004,
abstract = {The problem of pose estimation arises in many areas of computer vision, including object recognition, object tracking, site inspection and updating, and autonomous navigation when scene models are available. We present a new algorithm, called SoftPOSIT, for determining the pose of a 3D object from a single 2D image when correspondences between object points and image points are not known. The algorithm combines the iterative softassign algorithm (Gold and Rangarajan, 1996; Gold et al., 1998) for computing correspondences and the iterative POSIT algorithm (DeMenthon and Davis, 1995) for computing object pose under a full-perspective camera model. Our algorithm, unlike most previous algorithms for pose determination, does not have to hypothesize small sets of matches and then verify the remaining image points. Instead, all possible matches are treated identically throughout the search for an optimal pose. The performance of the algorithm is extensively evaluated in Monte Carlo simulations on synthetic data under a variety of levels of clutter, occlusion, and image noise. These tests show that the algorithm performs well in a variety of difficult scenarios, and empirical evidence suggests that the algorithm has an asymptotic run-time complexity that is better than previous methods by a factor of the number of image points. The algorithm is being applied to a number of practical autonomous vehicle navigation problems including the registration of 3D architectural models of a city to images, and the docking of small robots onto larger robots.},
author = {David, Philip and Dementhon, Daniel and Duraiswami, Ramani and Samet, Hanan},
doi = {10.1023/B:VISI.0000025800.10423.1f},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Autonomous navigation,Object recognition,POSIT,Softassign},
month = {sep},
number = {3},
pages = {259--284},
publisher = {Springer},
title = {{SoftPOSIT: Simultaneous pose and correspondence determination}},
url = {https://link.springer.com/article/10.1023/B:VISI.0000025800.10423.1f},
volume = {59},
year = {2004}
}
@article{Mellado_2014_super4pcs,
abstract = {Data acquisition in large‐scale scenes regularly involves accumulating information across multiple scans. A common approach is to locally align scan pairs using Iterative Closest Point (ICP) algorithm (or its variants), but requires static scenes and small motion between scan pairs. This prevents accumulating data across multiple scan sessions and/or different acquisition modalities (e.g., stereo, depth scans). Alternatively, one can use a global registration algorithm allowing scans to be in arbitrary initial poses. The state‐of‐the‐art global registration algorithm, 4PCS, however has a quadratic time complexity in the number of data points. This vastly limits its applicability to acquisition of large environments. We present Super 4PCS for global pointcloud registration that is optimal, i.e., runs in linear time (in the number of data points) and is also output sensitive in the complexity of the alignment problem based on the (unknown) overlap across scan pairs. Technically, we map the algorithm as an ‘instance problem' and solve it efficiently using a smart indexing data organization. The algorithm is simple, memory‐efficient, and fast. We demonstrate that Super 4PCS results in significant speedup over alternative approaches and allows unstructured efficient acquisition of scenes at scales previously not possible. Complete source code and datasets are available for research use at http://geometry.cs.ucl.ac.uk/projects/2014/super4PCS/.},
author = {Mellado, Nicolas and Aiger, Dror and Mitra, Niloy J},
doi = {10.1111/cgf.12446},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/SUPER 4PCS Fast Global Pointcloud Registration via Smart Indexing{\_}Mellado{\_}2014.pdf:pdf},
journal = {Computer Graphics Forum},
number = {5},
pages = {205--215},
title = {{SUPER 4PCS Fast Global Pointcloud Registration via Smart Indexing}},
volume = {33},
year = {2014}
}
@article{sekikawa2019tabulated,
author = {Sekikawa, Yusuke and Suzuki, Teppei},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Tabulated MLP for Fast Point Feature Embedding{\_}Sekikawa{\_}2019.pdf:pdf},
journal = {arXiv preprint arXiv:1912.00790},
title = {{Tabulated MLP for Fast Point Feature Embedding}},
year = {2019}
}
@article{Gojcic2019,
abstract = {We propose 3DSmoothNet, a full workflow to match 3D point clouds with a siamese deep learning architecture and fully convolutional layers using a voxelized smoothed density value (SDV) representation. The latter is computed per interest point and aligned to the local reference frame (LRF) to achieve rotation invariance. Our compact, learned, rotation invariant 3D point cloud descriptor achieves 94.9{\%} average recall on the 3DMatch benchmark data set, outperforming the state-of-the-art by more than 20 percent points with only 32 output dimensions. This very low output dimension allows for near realtime correspondence search with 0.1 ms per feature point on a standard PC. Our approach is sensor-and scene-agnostic because of SDV, LRF and learning highly descriptive features with fully convolutional layers. We show that 3DSmoothNet trained only on RGB-D indoor scenes of buildings achieves 79.0{\%} average recall on laser scans of outdoor vegetation, more than double the performance of our closest, learning-based competitors. Code, data and pre-trained models are available online at https://github.com/zgojcic/3DSmoothNet.},
author = {Gojcic, Zan and Zhou, Caifa and Wegner, Jan D. and Wieser, Andreas},
doi = {10.1109/CVPR.2019.00569},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/The Perfect Match{\_} 3D Point Cloud Matching with Smoothed Densities{\_}Gojcic{\_}2019.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {3D from Multiview and Sensors,Categorization,Recognition: Detection,Representation Learning,Retrieval,Scene Analysis and Under},
pages = {5540--5549},
title = {{The perfect match: 3D point cloud matching with smoothed densities}},
volume = {2019-June},
year = {2019}
}
@article{YI20171,
abstract = {We present a method for automatic reconstruction of the volumetric structures of urban buildings, directly from raw LiDAR point clouds. Given the large-scale LiDAR data from a group of urban buildings, we take advantage of the “divide-and-conquer” strategy to decompose the entire point clouds into a number of subsets, each of which corresponds to an individual building. For each urban building, we determine its upward direction and partition the corresponding point data into a series of consecutive blocks, achieved by investigating the distributions of feature points of the building along the upward direction. Next, we propose a novel algorithm, Spectral Residual Clustering (SRC), to extract the primitive elements within the contours of blocks from the sectional point set, which is formed by registering the series of consecutive slicing points. Subsequently, we detect the geometric constraints among primitive elements through individual fitting, and perform constrained fitting over all primitive elements to obtain the accurate contour. On this basis, we execute 3D modeling operations, like extrusion, lofting or sweeping, to generate the 3D models of blocks. The final accurate 3D models are generated by applying the union Boolean operations over the block models. We evaluate our reconstruction method on a variety of raw LiDAR scans to verify its robustness and effectiveness.},
author = {Yi, Cheng and Zhang, Yuan and Wu, Qiaoyun and Xu, Yabin and Remil, Oussama and Wei, Mingqiang and Wang, Jun},
doi = {https://doi.org/10.1016/j.cad.2017.07.005},
file = {:home/alan/Documents/MAS/SS20/ASW/Papers/Collection/Urban building reconstruction from raw LiDAR point data{\_}Yi{\_}2017.pdf:pdf},
issn = {0010-4485},
journal = {Computer-Aided Design},
keywords = {Contour extraction,Model reconstruction,Raw LiDAR data,Urban building},
pages = {1--14},
title = {{Urban building reconstruction from raw LiDAR point data}},
url = {http://www.sciencedirect.com/science/article/pii/S0010448517301331},
volume = {93},
year = {2017}
}
@inbook{Pilgrim_2009_XML,
abstract = {Most of the chapters in this book have centered around a piece of sample code. But XML isn't about code; it's about data. One common use of XML is ``syndication feeds'' that list the latest articles on a blog, forum, or other frequently-updated web site. Most popular blogging software can produce a feed and update it whenever new articles, discussion threads, or blog posts are published. You can follow a blog by ``subscribing'' to its feed, and you can follow multiple blogs with a dedicated ``feed aggregator'' like Google Reader.},
address = {Berkeley, CA},
author = {Pilgrim, Mark},
booktitle = {Dive Into Python 3},
doi = {10.1007/978-1-4302-2416-7_12},
isbn = {978-1-4302-2416-7},
pages = {185--204},
publisher = {Apress},
title = {{XML}},
url = {https://doi.org/10.1007/978-1-4302-2416-7{\_}12},
year = {2009}
}
